# Blind Video Deflickering by Neural Filtering with a Flawed Atlas

<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>

> **Blind Video Deflickering by Neural Filtering with a Flawed Atlas** <br>
> Chenyang Lei*, Xuanchi Ren*, Zhaoxiang Zhang and Qifeng Chen <br>
> *preprint*<br>
> \* indicates equal contribution 

[[Paper (Coming soon)]()]
[[ArXiv (Coming soon)]()]
[[Demo Page](https://chenyanglei.github.io/deflicker/)]
<!-- [[Appendix](https://xuanchiren.com/pub/DisCo_appendix.pdf)] -->


<div align="center">
  <br><br>
  <img src="demo.gif" alt="this slowpoke moves"  width="700" />
</div>

<br><br>
<p align="center">:construction: :pick: :hammer_and_wrench: :construction_worker:</p>
<p align="center">Here, we will release code and checkpoints in the near future! Stay tuned!</p>
<br><br>

# Discussion and Related work
If an input consistent video is available, you can try our previous work [NeurIPS 2020 Deep Video Prior](https://github.com/ChenyangLEI/deep-video-prior). Deep Video Prior can be utilized to improve the temporal consistency Image-to-Image Translation Models (e.g., ControlNet, Pix2Pix).

Solving the temporal inconsistency of video content is not in the scope of this paper or Deep Video Prior. For example, the contents obtained by video generation algorithms can be very different. Undesired shaky motion during video recording can also result in unstable videos. We leave the study for these types of video inconsistency to future work.


# NewsÔºÅ
- Mar 1, 2023: Paper will be public in one week. 
- Feb 28, 2023: Our paper is accepted by CVPR 2023, code will be released in two weeks. 
